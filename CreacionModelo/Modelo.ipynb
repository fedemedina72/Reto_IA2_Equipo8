{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:39:06.871872: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from datetime import date\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import threading\n",
    "\n",
    "import io\n",
    "from google.cloud import storage\n",
    "from IPython.display import Image\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import auth\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para actualizar la asistencia en la base de datos\n",
    "def update_attendance(row, asistencias):\n",
    "\n",
    "    if row['fecha'] == date.today() and row['id'] in asistencias:\n",
    "        result = asistencias[row['id']]\n",
    "    else:\n",
    "        result = row['asistencia']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_participacion(row, hand_counts):\n",
    "    # Asegurarse de que el nombre del alumno esté en los conteos de manos\n",
    "    if row['LocalID'] in hand_counts:\n",
    "        # Actualizar la participación para el alumno identificado\n",
    "        participacion_actual = row['Participacion']\n",
    "        nueva_participacion = participacion_actual + hand_counts[row['LocalID']]\n",
    "        return nueva_participacion\n",
    "    else:\n",
    "        # Si el alumno no está en los conteos de manos, mantener el valor actual de participación\n",
    "        return row['Participacion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para actualizar la asistencia en la base de datos\n",
    "def update_attendance(row, asistencias):\n",
    "    if row['LocalID'] in asistencias:\n",
    "        return asistencias[row['LocalID']]\n",
    "    else:\n",
    "        return row['Asistencia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener los ids de alumnes en cada clase\n",
    "def id_alumnes(clave, grupo, fire):\n",
    "    doc_ref = fire.collection(clave).document(grupo)\n",
    "    doc = doc_ref.get()\n",
    "    if doc.exists:\n",
    "        correos = [element.lower() + '@tec.mx' for element in doc.to_dict()['Alumnes']]\n",
    "        uids = [auth.get_user_by_email(email).uid for email in correos]\n",
    "        return uids\n",
    "\n",
    "    else:\n",
    "        print(\"La clase no existe\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el módulo de manos de MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Función para detectar manos y obtener puntos clave en un fotograma\n",
    "def detect_hand_landmarks(frame):\n",
    "    # Convertir la imagen a RGB (MediaPipe requiere imágenes en formato RGB)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Obtener las manos detectadas\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    # Lista para almacenar los puntos clave de la mano\n",
    "    hand_landmarks = []\n",
    "\n",
    "    # Verificar si se detectaron manos\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmark in results.multi_hand_landmarks:\n",
    "            landmarks = [(landmark.x, landmark.y) for landmark in hand_landmark.landmark]\n",
    "            hand_landmarks.append(landmarks)\n",
    "\n",
    "     # Lista para almacenar las puntas de los dedos de la mano\n",
    "    hand_fingertips = []\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmark in results.multi_hand_landmarks:\n",
    "            # Obtener la posición de la punta del dedo medio\n",
    "            fingertip = (hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x,\n",
    "                         hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y)\n",
    "            hand_fingertips.append(fingertip)\n",
    "\n",
    "    return hand_landmarks, hand_fingertips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud conexión\n",
    "# Llave para autenticacion del cliente\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/fernandaalcubilla/Desktop/IA-2/Reto/Interfaz/skilled-orbit-401601-1c9280b4aa9b.json'\n",
    "\n",
    "# Inizializar el cliente\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('equipo8-ia2')\n",
    "\n",
    "# Inicialización firestore\n",
    "cred = credentials.Certificate('/Users/fernandaalcubilla/Desktop/IA-2/Reto/Interfaz/usuariosia8-firebase-adminsdk-9gu37-23182c948b.json')\n",
    "firebase_admin.initialize_app(cred)\n",
    "fire = firestore.client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clave = 'TC3006C'\n",
    "grupo = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_names = id_alumnes(clave, grupo, fire)\n",
    "if known_face_names:\n",
    "    known_face_encodings = []\n",
    "    # Base de datos para guardar asistencia y participación\n",
    "    db = pd.DataFrame.from_records([(date.today(), x, '', 0) for x in known_face_names], columns =['Fecha', 'LocalID', 'Asistencia', 'Participacion'])\n",
    "    for uid in known_face_names:\n",
    "        blob = bucket.blob('Fotos_caras/'+uid+'.jpg')\n",
    "\n",
    "        face = face_recognition.load_image_file(io.BytesIO(blob.download_as_bytes()))\n",
    "        face_face_encoding = face_recognition.face_encodings(face)[0]\n",
    "        known_face_encodings.append(face_face_encoding)\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "    video_capture = cv2.VideoCapture(0) # Inicio de camara 0\n",
    "\n",
    "    hand_raised_threshold = 0.0004 # Umbral para determinar si la mano está levantada\n",
    "    asistencias = {name: 0 for name in known_face_names}\n",
    "    hand_counts = {name: 0 for name in known_face_names}\n",
    "    frames_count = 0\n",
    "\n",
    "    hand_raised_previous = False\n",
    "    process_this_frame = True\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Se agarra un solo frame del video\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # Detectar manos y obtener puntos clave\n",
    "        all_hand_points, hand_fingertips = detect_hand_landmarks(frame)\n",
    "\n",
    "        # Solo se procesan algunos frames para ahorrar tiempo\n",
    "        if process_this_frame:\n",
    "            frames_count += 1\n",
    "            # Hacer el frame 1/4 de su tamaño original\n",
    "            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "            rgb_small_frame = small_frame\n",
    "            \n",
    "            # Encontrar todas las caras y codigos en el frame\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "            face_names = []\n",
    "            for face_encoding in face_encodings:\n",
    "                # Verifica si la cara hace match con alguna del dataset\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                name = \"Unknown\"\n",
    "\n",
    "                # En caso de que tenga dudas, pone la cara mas cerca a la de alguna del dataset\n",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                    asistencias[name] = asistencias[name] + 1\n",
    "                face_names.append(name)\n",
    "\n",
    "        process_this_frame = not process_this_frame\n",
    "        ret, frame = video_capture.read()\n",
    "                \n",
    "        # Cambiar de tamaño de la imagen\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "\n",
    "        # VERIFICAR ROSTROS Y ASISTENCIA\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            # Volver a poner las imagenes en tamaño orignal antes de reducirla a 1/4 de su tamaño\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            # Poner la caja alrededor de las caras\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Poner los labels de las caras en la caja\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        # VERIFICAR SI HAY ALGUNA MANO LEVANTADA\n",
    "        for i, hand_points in enumerate(all_hand_points):\n",
    "            # Obtener la posición y de la punta del dedo medio (puedes ajustar esto según tu preferencia)\n",
    "            if i < len(face_names):\n",
    "                tip_of_middle_finger_y = hand_points[12][1] if len(hand_points) > 15 else 0\n",
    "\n",
    "                # Determinar si la mano está levantada\n",
    "                hand_raised = tip_of_middle_finger_y < hand_raised_threshold * frame.shape[0]\n",
    "\n",
    "                # Si la mano está levantada y no estaba levantada en el frame anterior\n",
    "                name = face_names[i]\n",
    "                if hand_raised and not hand_raised_previous:\n",
    "                    if name in hand_counts:\n",
    "                        hand_counts[name] = hand_counts[name] + 1\n",
    "                        \n",
    "                # Actualizar la bandera para el próximo frame\n",
    "                hand_raised_previous = hand_raised\n",
    "\n",
    "\n",
    "            # Dibujar un círculo en la punta del dedo medio (solo para visualización)\n",
    "            cv2.circle(frame, (int(hand_points[12][0] * frame.shape[1]), int(hand_points[12][1] * frame.shape[0])),\n",
    "                    5, (0, 255, 0), -1)\n",
    "\n",
    "            # Dibujar un texto indicando si la mano está levantada\n",
    "            cv2.putText(frame, f\"Mano {i + 1} - Levantada: {hand_raised}\", (10, 30 + i * 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0) if hand_raised else (0, 0, 255), 2)\n",
    "            \n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release handle to the webcam\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    valores = np.fromiter(asistencias.values(), dtype=float)\n",
    "    # Dividimos todos los valores por el número de frames\n",
    "    divided_values = valores / frames_count\n",
    "\n",
    "    # Rango para convertir a cualitativo\n",
    "    conditions = [\n",
    "        (divided_values >= 0) & (divided_values <= .05),\n",
    "        (divided_values > .05) & (divided_values <= .20),\n",
    "        (divided_values > .20) & (divided_values <= .60),\n",
    "        (divided_values > .60)\n",
    "    ]\n",
    "    choices = ['Inasistencia', 'Bajo' ,'Medio', 'Alto']\n",
    "    rango_valores = np.select(conditions, choices, default='Unknown')\n",
    "    asistencias = dict(zip(asistencias.keys(), rango_valores))\n",
    "\n",
    "    # Actualizar asistencia\n",
    "    db['Participacion'] = db.apply(update_participacion, axis=1, args=(hand_counts,))\n",
    "    db['Asistencia'] = db.apply(update_attendance, axis=1, args=(asistencias,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>LocalID</th>\n",
       "      <th>Asistencia</th>\n",
       "      <th>Participacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>H7ry96mrFhW9Gg4YCNRM8zmAB9o2</td>\n",
       "      <td>Inasistencia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>Cs3yJrR6PtbfnZFRx7TL0Q3EUqv1</td>\n",
       "      <td>Medio</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>Xl7cRHJaircpk2wZQoqLCbvfyIc2</td>\n",
       "      <td>Inasistencia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fecha                       LocalID    Asistencia  Participacion\n",
       "0  2023-11-22  H7ry96mrFhW9Gg4YCNRM8zmAB9o2  Inasistencia              0\n",
       "1  2023-11-22  Cs3yJrR6PtbfnZFRx7TL0Q3EUqv1         Medio              2\n",
       "2  2023-11-22  Xl7cRHJaircpk2wZQoqLCbvfyIc2  Inasistencia              0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subir db de Asistencia y participación a la nube\n",
    "# Cree un objeto Blob que represente el archivo parquet que desea cargar.\n",
    "blob = bucket.blob('Cursos/'+clave+'/'+grupo+'/' + str(date.today()) + '.parquet')\n",
    "\n",
    "# Sube el dataframe directamente a Google Storage como un string.\n",
    "blob.upload_from_string(db.to_parquet(compression='gzip'), '.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
